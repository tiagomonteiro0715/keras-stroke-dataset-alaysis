{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "roman-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "previous-plain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56669</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "5  56669    Male  81.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level  bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69   36  formerly smoked   \n",
       "2        Private          Rural             105.92   32     never smoked   \n",
       "3        Private          Urban             171.23   34           smokes   \n",
       "4  Self-employed          Rural             174.12   24     never smoked   \n",
       "5        Private          Urban             186.21   29  formerly smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_used = pd.read_csv(r\"C:\\Users\\tiago\\Desktop\\code-projects\\working\\stroke prediction\\healthcare-dataset-stroke-data.csv\" , keep_default_na=False)\n",
    "df = data_used.copy()\n",
    "df = df[df.bmi != \"N/A\"]\n",
    "df['bmi'] = df['bmi'].astype('float64')\n",
    "df = df.astype({\"bmi\":'int'}) \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adolescent-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataframe = df.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = df.drop(val_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfied-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"stroke\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spread-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acting-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "double-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string_categorical_feature(feature, name, dataset):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    index = StringLookup()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = index(feature)\n",
    "\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a dataset of indices\n",
    "    feature_ds = feature_ds.map(index)\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(encoded_feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "german-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_integer_categorical_feature(feature, name, dataset):\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlimited-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers\n",
    "hypertension = keras.Input(shape=(1,), name=\"hypertension\", dtype=\"int64\")\n",
    "heart_disease = keras.Input(shape=(1,), name=\"heart_disease\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "gender = keras.Input(shape=(1,), name=\"gender\", dtype=\"string\")\n",
    "ever_married = keras.Input(shape=(1,), name=\"ever_married\", dtype=\"string\")\n",
    "work_type = keras.Input(shape=(1,), name=\"work_type\", dtype=\"string\")\n",
    "Residence_type = keras.Input(shape=(1,), name=\"Residence_type\", dtype=\"string\")\n",
    "smoking_status = keras.Input(shape=(1,), name=\"smoking_status\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "avg_glucose_level = keras.Input(shape=(1,), name=\"avg_glucose_level\")\n",
    "bmi = keras.Input(shape=(1,), name=\"bmi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controlling-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = [\n",
    "    hypertension,\n",
    "    heart_disease,\n",
    "    gender,\n",
    "    ever_married,\n",
    "    work_type,\n",
    "    Residence_type,\n",
    "    smoking_status,\n",
    "    age,\n",
    "    avg_glucose_level,\n",
    "    bmi,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "essential-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer categorical features\n",
    "hypertension_encoded = encode_integer_categorical_feature(hypertension, \"hypertension\", train_ds)\n",
    "heart_disease_encoded = encode_integer_categorical_feature(heart_disease, \"heart_disease\", train_ds)\n",
    "\n",
    "# String categorical features\n",
    "gender_encoded = encode_string_categorical_feature(gender, \"gender\", train_ds)\n",
    "ever_married_encoded = encode_string_categorical_feature(ever_married, \"ever_married\", train_ds)\n",
    "work_type_encoded = encode_string_categorical_feature(work_type, \"work_type\", train_ds)\n",
    "Residence_type_encoded = encode_string_categorical_feature(Residence_type, \"Residence_type\", train_ds)\n",
    "smoking_status_encoded = encode_string_categorical_feature(smoking_status, \"smoking_status\", train_ds)\n",
    "\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "avg_glucose_level_encoded = encode_numerical_feature(avg_glucose_level, \"avg_glucose_level\", train_ds)\n",
    "bmi_encoded = encode_numerical_feature(bmi, \"bmi\", train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "celtic-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        hypertension_encoded,\n",
    "        heart_disease_encoded,\n",
    "        gender_encoded,\n",
    "        ever_married_encoded,\n",
    "        work_type_encoded,\n",
    "        Residence_type_encoded,\n",
    "        smoking_status_encoded,\n",
    "        age_encoded,\n",
    "        avg_glucose_level_encoded,\n",
    "        bmi_encoded,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "miniature-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "still-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago\\.virtualenvs\\tensorflow--VJ90gqx\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 2s 7ms/step - loss: 0.5508 - accuracy: 0.7227 - val_loss: 0.1754 - val_accuracy: 0.9603\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9544 - val_loss: 0.1475 - val_accuracy: 0.9603\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9555 - val_loss: 0.1395 - val_accuracy: 0.9603\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9584 - val_loss: 0.1362 - val_accuracy: 0.9603\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9559 - val_loss: 0.1341 - val_accuracy: 0.9603\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9576 - val_loss: 0.1331 - val_accuracy: 0.9603\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9530 - val_loss: 0.1318 - val_accuracy: 0.9603\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9584 - val_loss: 0.1314 - val_accuracy: 0.9603\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9487 - val_loss: 0.1314 - val_accuracy: 0.9603\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9541 - val_loss: 0.1313 - val_accuracy: 0.9603\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9539 - val_loss: 0.1307 - val_accuracy: 0.9603\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9565 - val_loss: 0.1310 - val_accuracy: 0.9603\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9524 - val_loss: 0.1307 - val_accuracy: 0.9603\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9527 - val_loss: 0.1306 - val_accuracy: 0.9603\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9555 - val_loss: 0.1304 - val_accuracy: 0.9603\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9629 - val_loss: 0.1313 - val_accuracy: 0.9613\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9617 - val_loss: 0.1315 - val_accuracy: 0.9603\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9617 - val_loss: 0.1315 - val_accuracy: 0.9603\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9610 - val_loss: 0.1319 - val_accuracy: 0.9603\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9530 - val_loss: 0.1317 - val_accuracy: 0.9603\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9581 - val_loss: 0.1318 - val_accuracy: 0.9603\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9564 - val_loss: 0.1327 - val_accuracy: 0.9603\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9536 - val_loss: 0.1308 - val_accuracy: 0.9613\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9549 - val_loss: 0.1311 - val_accuracy: 0.9603\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9583 - val_loss: 0.1310 - val_accuracy: 0.9603\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9614 - val_loss: 0.1321 - val_accuracy: 0.9613\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9564 - val_loss: 0.1313 - val_accuracy: 0.9613\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9556 - val_loss: 0.1316 - val_accuracy: 0.9613\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9617 - val_loss: 0.1317 - val_accuracy: 0.9613\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9517 - val_loss: 0.1315 - val_accuracy: 0.9613\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9552 - val_loss: 0.1325 - val_accuracy: 0.9603\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9580 - val_loss: 0.1324 - val_accuracy: 0.9613\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9578 - val_loss: 0.1324 - val_accuracy: 0.9613\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9549 - val_loss: 0.1325 - val_accuracy: 0.9603\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9582 - val_loss: 0.1323 - val_accuracy: 0.9613\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9562 - val_loss: 0.1324 - val_accuracy: 0.9613\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9561 - val_loss: 0.1323 - val_accuracy: 0.9613\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9571 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9595 - val_loss: 0.1333 - val_accuracy: 0.9603\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9589 - val_loss: 0.1335 - val_accuracy: 0.9603\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9479 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9543 - val_loss: 0.1332 - val_accuracy: 0.9603\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9599 - val_loss: 0.1331 - val_accuracy: 0.9603\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9567 - val_loss: 0.1339 - val_accuracy: 0.9603\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9536 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9554 - val_loss: 0.1331 - val_accuracy: 0.9603\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1409 - accuracy: 0.9572 - val_loss: 0.1337 - val_accuracy: 0.9603\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9494 - val_loss: 0.1337 - val_accuracy: 0.9603\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9563 - val_loss: 0.1336 - val_accuracy: 0.9603\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9571 - val_loss: 0.1347 - val_accuracy: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c3f582f248>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "capital-surgery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This particular patient had a 15.3 percent probability of having a stroke, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"hypertension\": 1,\n",
    "    \"heart_disease\": 1,\n",
    "    \"gender\": \"Male\",\n",
    "    \"ever_married\": \"Yes\",\n",
    "    \"work_type\": \"Self-employed\",\n",
    "    \"Residence_type\": \"Urban\",\n",
    "    \"smoking_status\": \"smokes\",\n",
    "    \"age\": 60,\n",
    "    \"avg_glucose_level\": 174,\n",
    "    \"bmi\": 32,\n",
    "\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a stroke, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine learning",
   "language": "python",
   "name": "tensorflow--vj90gqx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
