{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stopped-arena",
   "metadata": {},
   "source": [
    "seguir regras do machine learning checklist\n",
    "\n",
    "https://github.com/tiagomonteiro0715/keras-predict-heart-disease/blob/main/main.ipynb\n",
    "\n",
    "https://keras.io/examples/structured_data/structured_data_classification_from_scratch/#the-dataset\n",
    "\n",
    "https://medium.com/@harsz89/how-to-drop-rows-based-on-column-values-using-pandas-dataframe-38cf50e4c95a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used = pd.read_csv(r\"C:\\Users\\tiago\\Desktop\\code-projects\\working\\stroke prediction\\healthcare-dataset-stroke-data.csv\" , keep_default_na=False)\n",
    "df = data_used.copy()\n",
    "df.head()\n",
    "df.dropna(subset=['bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataframe = df.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = df.drop(val_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"stroke\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string_categorical_feature(feature, name, dataset):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    index = StringLookup()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = index(feature)\n",
    "\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a dataset of indices\n",
    "    feature_ds = feature_ds.map(index)\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(encoded_feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_integer_categorical_feature(feature, name, dataset):\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers\n",
    "hypertension = keras.Input(shape=(1,), name=\"hypertension\", dtype=\"int64\")\n",
    "heart_disease = keras.Input(shape=(1,), name=\"heart_disease\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "gender = keras.Input(shape=(1,), name=\"gender\", dtype=\"string\")\n",
    "ever_married = keras.Input(shape=(1,), name=\"ever_married\", dtype=\"string\")\n",
    "work_type = keras.Input(shape=(1,), name=\"work_type\", dtype=\"string\")\n",
    "Residence_type = keras.Input(shape=(1,), name=\"Residence_type\", dtype=\"string\")\n",
    "smoking_status = keras.Input(shape=(1,), name=\"smoking_status\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "avg_glucose_level = keras.Input(shape=(1,), name=\"avg_glucose_level\")\n",
    "bmi = keras.Input(shape=(1,), name=\"bmi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = [\n",
    "    sex,\n",
    "    cp,\n",
    "    fbs,\n",
    "    restecg,\n",
    "    exang,\n",
    "    ca,\n",
    "    thal,\n",
    "    age,\n",
    "    trestbps,\n",
    "    chol,\n",
    "    thalach,\n",
    "    oldpeak,\n",
    "    slope,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer categorical features\n",
    "sex_encoded = encode_integer_categorical_feature(sex, \"sex\", train_ds)\n",
    "cp_encoded = encode_integer_categorical_feature(cp, \"cp\", train_ds)\n",
    "fbs_encoded = encode_integer_categorical_feature(fbs, \"fbs\", train_ds)\n",
    "restecg_encoded = encode_integer_categorical_feature(restecg, \"restecg\", train_ds)\n",
    "exang_encoded = encode_integer_categorical_feature(exang, \"exang\", train_ds)\n",
    "ca_encoded = encode_integer_categorical_feature(ca, \"ca\", train_ds)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_string_categorical_feature(thal, \"thal\", train_ds)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a stroke, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine learning",
   "language": "python",
   "name": "tensorflow--vj90gqx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
